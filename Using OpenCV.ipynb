{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using OpenCV\n",
    "## Overview\n",
    "This document exists to organize and contextualize a family of Python functions written by Phil Fahn-Lai for working with scientific videos using the open-source computer vision library [OpenCV](https://opencv.org/). The code shown here was originally developed in 2019/2020 to pre-process [XROMM](https://www.xromm.org/) videos in preparation for automated labeling by the deep learning toolbox [DeepLabCut](http://www.mousemotorlab.org/deeplabcut), and addresses several needs common to large video data sets (e.g. concatenating, trimming, downsampling, compressing), as well as a couple that were particular to this project (e.g. merging two separate streams of grayscale video into separate channels of a color video).\n",
    "## Prerequisites\n",
    "Both Python and OpenCV are platform-independent, and a number of detailed guides exist on the internet for setting them up on your computer, although Unix-like systems (e.g. Mac and Linux) are frequently friendlier development environments than Windows (for reasons we won't go into here.) \n",
    "\n",
    "[Anaconda](https://www.anaconda.com/) is a popular distribution of Python that includes a package manager (Conda), a user-friendly GUI for managing development environments (Navigator), and a code editor/IDE (Spyder), and is the easiest way to get up and running with Python without mucking around in the command line. Anaconda's intuitive approach to creating and managing environments makes it easy to recommend to beginners, as messed-up paths and missing or redundant dependencies can be a frustrating and discouraging barrier to learning to program.\n",
    "\n",
    "Going all-in on the convenience of the Anaconda ecosystem means also accepting its limitations: while many popular Python packages (e.g. NumPy, TensorFlow) are available on Conda's repositories, Conda's selection pales in comparison with the universe of code available through PIP, Python's default package manager. Several of the modules and packages (package = bundle of modules) required by the functions below (e.g. blend_modes) do not yet exist on Conda, and while it is possible to take their source code from PyPI (PIP's repository) and compile them for Conda, I have found that it is much quicker and far less frustrating to simply **handle environments with Anaconda** and **use PIP to install packages within them.**\n",
    "\n",
    "If you're reading this, you've probably gotten to the point where you've installed not only Python, but also [Jupyter Notebook/Lab](https://jupyter.org/). Jupyter is an IDE (Integrated Development Environment) analogous to RStudio or Spyder, but instead of running as a self-contained desktop application, Jupyter performs back-end calculations on a virtual server on your computer, and pipes the output to an interactive interface in your web browser. Jupyter notebooks (`.ipynb`) consist of text cells (written in formattable [Markdown](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet) (`.md`)) as well as executable code cells (written in Python). By allowing the results of computational analyses to be presented alongside the code that generated them as well as explanatory text, notebooks have become extremely popular with teachers (who value context and exposition), and data scientists (who value repeatability and (generally) transparency).\n",
    "\n",
    "## How to use\n",
    "Each code cell in this notebook contains the code of a single Python module. The project directory that these were taken from contained all of these modules as discrete `.py` files, as well as a `.ipynb` Jupyter notebook that imported them, like so: `from [module_filename] import [module_functionname]`. \n",
    "\n",
    "To actually use these functions, you should either replicate this folder structure or—preferably—decide to be more organized than I was and place them inside a subdirectory called 'modules' or some such, in which case you would import them with, e.g. `from .[subdirectory] import [module_filename]` (the `.` indicates that the path to the subdirectory is relative to the location of the file that's trying to import the module). Note that you can rename your imports for brevity—for instance, many people choose to `import numpy as np` so they can access the package's methods with `np.[function]` rather than `numpy.[function]`.\n",
    "\n",
    "Alternatively, you can create a new Jupyter notebook and copy the function cells you want to use into there. Two things to keep in mind if you do this: \n",
    "1. These functions use a lot of the same imports, so make sure to go through and delete the redundant ones (or ideally consolidate your imports in a separate code cell at the top of the notebook). \n",
    "2. Variables in notebooks are *globally-scoped*—they exist outside of the cells they're created in. Each code cell in your notebook has access to every other code cell, since they all share the same namespace. What this means in practice is you should be careful not to assign overly-similar names to variables in different parts of the notebook, so as not to run the risk of accidentally overwriting them later on.\n",
    "\n",
    "Or you could do the grown-up thing and wrap all of these inside a class.\n",
    "\n",
    "Finally, a word on path separators. While Unix-like systems use a regular (forward) slash `/` as a separator in file paths (e.g. `[directory]/[file]`), Windows uses a backslash `\\` instead (e.g. `[directory]\\[file]`). This can cause *huge* issues when working with languages that use the backslash as an escape character *(a lot of them!)* To get around this, make sure you pass strings containing Windows paths as raw strings (by adding `r` before the opening quote, e.g. `r'[directory]\\[file]'`)—this tells Python to treat the backslash literally, instead of as a prefix to a special character. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scanDir.py\n",
    "Loops recursively through a specified folder `directory` and returns a list of all files with a given extension *(defaults to `.avi` if unspecified)*. Optionally drops filenames containing `filter_string` (case-sensitive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "        \n",
    "def scanDir(directory, extension='avi', filters=[], filter_out=True, verbose=False):\n",
    "    file_list=[]\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for name in files:\n",
    "            if name.lower().endswith(extension):\n",
    "                filename = os.path.join(root, name)\n",
    "                if verbose == True:\n",
    "                    print(\"Found file with extension .\"+ extension + \": \" + filename)\n",
    "                file_list.append(filename)\n",
    "                continue\n",
    "            else:\n",
    "                continue\n",
    "    if len(filters) != 0:\n",
    "        if filter_out==True:\n",
    "            for string in filters:\n",
    "                file_list = [file for file in file_list if not re.search(string, file)]\n",
    "        else:\n",
    "            for string in filters:\n",
    "                file_list = [file for file in file_list if re.search(string, file)]\n",
    "    return(file_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cv2VideoWriterDummy.py\n",
    "Demonstrates how to open a video stream with OpenCV's VideoCapture class, and save it as either: \n",
    "1. An MPEG-4 video with H.264 compression[<sup>1</sup>](#fn1) (using the VideoWriter class, which calls FFMPEG under the hood but exposes very few options to the user), or \n",
    "2. As a stream of lossless `.PNGs` bound into an uncompressed `.AVI` (by piping the incoming video data to FFMPEG). \n",
    "\n",
    "<span id=\"fn1\"><sup>1</sup> This requires the [H.264/AVC codec](https://www.videolan.org/developers/x264.html). Use 'mp4v' for less-efficient Apple MPEG encoding if installing H.264 is not an option.</span>\n",
    "\n",
    "\n",
    "1) is much faster, but provides less control over the quality of the output video. \n",
    "\n",
    "2) is the only way to ensure near-zero degradation in video quality, but is quite a bit slower. \n",
    "\n",
    "A potential option 3) not shown here is to get OpenCV to output an uncompressed `.AVI` by passing it 0 as the codec, but this results in a file slightly larger than the original since there is no currently-working way to keep OpenCV from outputting a color video, and it is impossible to rule out data loss from converting between pixel formats. \n",
    "\n",
    "Option 4) is to pass the video data to FFMPEG as in 2), but use FFMPEG's much more comprehensive API to output a better-compressed video than OpenCV is capable of making. FFMPEG supports multiple lossless codecs (e.g. H.264 lossless, HUFFYUV, FFV1), and can be built to include next-generation H.265/HEVC support as well.\n",
    "\n",
    "Ultimately, the best choice for output encoding depends on the nature of the project—**there is no single perfect solution, as pretty much everything involving video is a tradeoff.** Uncompressed AVIs preserve maximum quality, but are unwieldy to deal with and can be slow to save. Opting for compressed videos means choosing between older, less-efficient codecs like MP4V/Apple MPEG-4 (quick to encode and decode, lower quality) and newer codecs like H.264 and H.265 that produce higher-quality videos at the cost of longer encoding and decoding times. For long-term archival purposes it might be worth investing the encoding time upfront to transcode data into a slow-to-decode lossless format, while for immediate analysis on relatively powerful hardware you should see if you can get away with compressing without losing scientifically-relevant amounts of data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from subprocess import Popen, PIPE\n",
    "import numpy as np\n",
    "import cv2\n",
    "        \n",
    "def cv2VideoWriterDummy(input_video, output_video, codec='avc1'):\n",
    "    cap = cv2.VideoCapture(input_video)\n",
    "    frame_width = int(cap.get(3))\n",
    "    frame_height = int(cap.get(4))\n",
    "    frame_rate = round(cap.get(5),2)\n",
    "    if codec == 'uncompressed':\n",
    "        pix_format = 'gray'   ##change to 'yuv420p' for color or 'gray' for grayscale. 'pal8' doesn't play on macs\n",
    "        p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(int(frame_rate)), '-i', '-', '-vcodec', 'rawvideo','-pix_fmt',pix_format,'-r', str(int(frame_rate)), output_video], stdin=PIPE)\n",
    "    else:\n",
    "        if codec == 0:\n",
    "            fourcc = 0\n",
    "        else:\n",
    "            fourcc = cv2.VideoWriter_fourcc(*codec)    \n",
    "        out = cv2.VideoWriter(output_video, \n",
    "                              fourcc, \n",
    "                              frame_rate,(frame_width, frame_height))\n",
    "        \n",
    "    while(cap.isOpened()):\n",
    "        ret, frame = cap.read()\n",
    "        if ret == True:\n",
    "            cv2.imshow('frame',frame)\n",
    "            if codec == 'uncompressed':\n",
    "                im = Image.fromarray(frame)\n",
    "                im.save(p.stdin, 'PNG') \n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "            else:\n",
    "                out.write(frame)\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "        else:\n",
    "            break\n",
    "    if codec == 'uncompressed':\n",
    "        p.stdin.close()\n",
    "        p.wait()\n",
    "    cap.release()\n",
    "    if codec != 'uncompressed':\n",
    "        out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### getImmediateAncestors.py\n",
    "Returns a list of a given path's immediate parent directories, in ascending order. Level is specified as `depth`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def getImmediateAncestors(file_path, depth=1):\n",
    "    result = []\n",
    "    for i in range(depth):\n",
    "        parent_path, child_name = os.path.split(file_path)\n",
    "        file_path = parent_path\n",
    "        result.append(child_name)\n",
    "    return result        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### changeFilename.py\n",
    "Given any filepath, inserts a custom string `insertion` at position `pos`. Default behavior is prefix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def changeFileName(file_path, insertion, new_extension=None, pos=0):\n",
    "    location, name = os.path.split(file_path)\n",
    "    left, right = name[:pos], name[pos:]\n",
    "    modified_name = left + insertion + right\n",
    "    if new_extension != None:\n",
    "        temp_name, old_ext = os.path.splitext(modified_name)\n",
    "        modified_name = temp_name + new_extension\n",
    "    result = os.path.join(location, modified_name)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bakeMetadata.py\n",
    "Bakes experiment metadata (Experiment day, trial condition, frame number) into each video frame. Expects the following folder structure: `[experiment]/[trial]/[video]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from subprocess import Popen, PIPE\n",
    "import numpy as np\n",
    "import cv2\n",
    "# from getImmediateAncestors import getImmediateAncestors\n",
    "        \n",
    "def bakeMetadata(input_path, output_path, codec='avc1'):\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    frame_width = int(cap.get(3))\n",
    "    frame_height = int(cap.get(4))\n",
    "    frame_rate = round(cap.get(5),2)\n",
    "    \n",
    "\n",
    "    pos_x = round(frame_width/50)\n",
    "    off_y = round(frame_height/50)\n",
    "    off_y_initial = off_y\n",
    "    frame_index = 1\n",
    "    metadata = getImmediateAncestors(input_path, 3)[1:]\n",
    "    metadata.append(frame_index)\n",
    "    font_family = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    font_size = 0.4\n",
    "    font_color = (255, 255, 255)\n",
    "    \n",
    "    if codec == 'uncompressed':\n",
    "        pix_format = 'gray'   ##change to 'yuv420p' for color or 'gray' for grayscale. 'pal8' doesn't play on macs\n",
    "        p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(int(frame_rate)), '-i', '-', '-vcodec', 'rawvideo','-pix_fmt',pix_format,'-r', str(int(frame_rate)), output_video], stdin=PIPE)\n",
    "    else:\n",
    "        if codec == 0:\n",
    "            fourcc = 0\n",
    "        else:\n",
    "            fourcc = cv2.VideoWriter_fourcc(*codec)    \n",
    "        out = cv2.VideoWriter(output_path, \n",
    "                              fourcc, \n",
    "                              frame_rate,(frame_width, frame_height))\n",
    "        \n",
    "    while(cap.isOpened()):\n",
    "        ret, frame = cap.read()\n",
    "        if ret == True:\n",
    "            off_y = off_y_initial\n",
    "            for metadatum in metadata:\n",
    "                pos_y = frame_height-off_y\n",
    "\n",
    "                frame = cv2.putText(frame, str(metadatum), (pos_x, pos_y), font_family,\n",
    "                                    font_size, font_color)\n",
    "                off_y = off_y+off_y_initial \n",
    "            cv2.imshow('frame',frame)\n",
    "            frame_index += 1\n",
    "            metadata.pop()\n",
    "            metadata.append(frame_index)\n",
    "            if codec == 'uncompressed':\n",
    "                im = Image.fromarray(frame)\n",
    "                im.save(p.stdin, 'PNG') \n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    breakw\n",
    "            else:\n",
    "                out.write(frame)\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "        else:\n",
    "            break\n",
    "    if codec == 'uncompressed':\n",
    "        p.stdin.close()\n",
    "        p.wait()\n",
    "    cap.release()\n",
    "    if codec != 'uncompressed':\n",
    "        out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sortByCameraID.py\n",
    "Given a list of file paths, returns a list of lists sorted by camera identifier (in the format prefix->camera#)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def sortByCameraID(path_list, prefixes=['Cam','C00'], number_of_cameras=2):\n",
    "    triaged_lists = [[] for cameras in range(number_of_cameras)]\n",
    "    for i, triaged_list in enumerate(triaged_lists, start=1):\n",
    "        for path in path_list:\n",
    "            for prefix in prefixes:\n",
    "                match_string = prefix+str(i)\n",
    "                if re.search(match_string, path):\n",
    "                    triaged_list.append(path)\n",
    "                    break\n",
    "    return triaged_lists\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### concatenateVideos.py\n",
    "Given a list of video paths, concatenates them into one long video. Passing in an optional downsampling factor tells the function to only capture one in every n frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "        \n",
    "def concatenateVideos(path_list, output_path, codec='avc1', interval=1):\n",
    "    frame_index = 0\n",
    "    video_index = 0\n",
    "    cap = cv2.VideoCapture(path_list[0])\n",
    "    frame_width = int(cap.get(3))\n",
    "    frame_height = int(cap.get(4))\n",
    "    frame_rate = round(cap.get(5),2)/interval\n",
    "    fourcc = cv2.VideoWriter_fourcc(*codec)\n",
    "    out = cv2.VideoWriter(output_path, \n",
    "                          fourcc, \n",
    "                          frame_rate,(frame_width, frame_height))\n",
    "    while(cap.isOpened()):\n",
    "        ret, frame = cap.read()\n",
    "        frame_index += 1\n",
    "        if frame is None:\n",
    "            print(\"end of video \" + str(video_index) + \" ... next one now\")\n",
    "            video_index += 1\n",
    "            if video_index >= len(path_list):\n",
    "                break\n",
    "            cap = cv2.VideoCapture(path_list[ video_index ])\n",
    "            frame_index = 0\n",
    "        elif frame_index == interval:\n",
    "            frame = frame.astype(np.uint8)\n",
    "            cv2.imshow('frame',frame)\n",
    "            out.write(frame)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "            frame_index = 0         \n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"done!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mergeRGB.py\n",
    "Takes a dictionary containing two video paths in the format `{'A':[path A], 'B':[path B]}` and exports a single new video with video A written to the red channel and video B written to the green channel. The blue channel is, depending on the value passed as \"mode\", either the difference blend between A and B, the multiply blend, or just a black frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import blend_modes\n",
    "        \n",
    "def mergeRGB(video_dict, output_path, codec='avc1', mode=None):\n",
    "    capA = cv2.VideoCapture(video_dict['A'])\n",
    "    capB = cv2.VideoCapture(video_dict['B'])\n",
    "    frame_width = int(capA.get(3))\n",
    "    frame_height = int(capA.get(4))\n",
    "    frame_rate = round(capA.get(5),2)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*codec)\n",
    "    out = cv2.VideoWriter(output_path,\n",
    "                         fourcc,\n",
    "                         frame_rate,(frame_width, frame_height))\n",
    "    while(capA.isOpened()):\n",
    "        retA, frameA = capA.read()\n",
    "        retB, frameB = capB.read()\n",
    "        if retA == True:\n",
    "            ## give frames an alpha channel to prepare for blending; blend_modes requires 32bit\n",
    "            frameA = cv2.cvtColor(frameA, cv2.COLOR_BGR2BGRA,4).astype(np.float32)\n",
    "            frameB = cv2.cvtColor(frameB, cv2.COLOR_BGR2BGRA,4).astype(np.float32)\n",
    "            frameA = cv2.normalize(frameA, None, 0, 255, norm_type=cv2.NORM_MINMAX)\n",
    "            frameB = cv2.normalize(frameB, None, 0, 255, norm_type=cv2.NORM_MINMAX)\n",
    "            if mode == \"difference\":\n",
    "                extraChannel = blend_modes.difference(frameA,frameB,1)\n",
    "            elif mode == \"multiply\":\n",
    "                extraChannel = blend_modes.multiply(frameA,frameB,1)\n",
    "            else:\n",
    "                extraChannel = np.zeros((frame_width, frame_height,3),np.uint8)\n",
    "                extraChannel = cv2.cvtColor(extraChannel, cv2.COLOR_BGR2BGRA,4).astype(np.float32)\n",
    "\n",
    "            ## get rid of alpha channel in preparation for converting back to grayscale; opencv prefers 8bit\n",
    "            frameA = cv2.cvtColor(frameA, cv2.COLOR_BGRA2BGR).astype(np.uint8)  \n",
    "            frameB = cv2.cvtColor(frameB, cv2.COLOR_BGRA2BGR).astype(np.uint8)  \n",
    "            extraChannel = cv2.cvtColor(extraChannel, cv2.COLOR_BGRA2BGR).astype(np.uint8)  \n",
    "\n",
    "            ## convert to grayscale so we can merge into 3-channel image\n",
    "            frameA = cv2.cvtColor(frameA, cv2.COLOR_BGR2GRAY)  \n",
    "            frameB = cv2.cvtColor(frameB, cv2.COLOR_BGR2GRAY)  \n",
    "            extraChannel = cv2.cvtColor(extraChannel, cv2.COLOR_BGR2GRAY)  \n",
    "\n",
    "            ## merge, show and write                  \n",
    "            merged = cv2.merge((extraChannel, frameB, frameA))\n",
    "            cv2.imshow('merged',merged)\n",
    "            out.write(merged)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "    capA.release()\n",
    "    capB.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"done!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### splitRGB.py\n",
    "Takes a RGB video with different grayscale data written to the R, G, and B channels and splits it back into its component source videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from subprocess import Popen, PIPE\n",
    "        \n",
    "def splitRGB(input_path, codec='avc1'):\n",
    "    out_name = os.path.splitext(os.path.basename(input_path))[0]+'_split_'\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    frame_width = int(cap.get(3))\n",
    "    frame_height = int(cap.get(4))\n",
    "    frame_rate = round(cap.get(5),2)\n",
    "    if codec == 'uncompressed':\n",
    "        pix_format = 'gray'   ##change to 'yuv420p' for color or 'gray' for grayscale. 'pal8' doesn't play on macs\n",
    "        p1 = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(int(frame_rate)), '-i', '-', '-vcodec', 'rawvideo','-pix_fmt',pix_format,'-r', str(int(frame_rate)), out_name+'c1.avi'], stdin=PIPE)\n",
    "        p2 = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(int(frame_rate)), '-i', '-', '-vcodec', 'rawvideo','-pix_fmt',pix_format,'-r', str(int(frame_rate)), out_name+'c2.avi'], stdin=PIPE)\n",
    "    else:\n",
    "        if codec == 0:\n",
    "            fourcc = 0\n",
    "        else:\n",
    "            fourcc = cv2.VideoWriter_fourcc(*codec)    \n",
    "        out1 = cv2.VideoWriter(out_name+'c1.mp4', \n",
    "                              fourcc, \n",
    "                              frame_rate,(frame_width, frame_height))\n",
    "        out2 = cv2.VideoWriter(out_name+'c2.mp4', \n",
    "                              fourcc, \n",
    "                              frame_rate,(frame_width, frame_height))\n",
    "        \n",
    "    while(cap.isOpened()):\n",
    "        ret, frame = cap.read()\n",
    "        if ret == True:\n",
    "            B, G, R = cv2.split(frame)\n",
    "            cv2.imshow('frame',R)\n",
    "            if codec == 'uncompressed':\n",
    "                imR = Image.fromarray(R)\n",
    "                imG = Image.fromarray(G)\n",
    "                imR.save(p1.stdin, 'PNG') \n",
    "                imG.save(p2.stdin, 'PNG') \n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "            else:\n",
    "                out1.write(R)\n",
    "                out2.write(G)\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "        else:\n",
    "            break\n",
    "    if codec == 'uncompressed':\n",
    "        p1.stdin.close()\n",
    "        p1.wait()\n",
    "        p2.stdin.close()\n",
    "        p2.wait()\n",
    "    cap.release()\n",
    "    if codec != 'uncompressed':\n",
    "        out1.release()\n",
    "        out2.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vidToPngs.py\n",
    "Takes a video as input and exports each frame as a separate .png."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "        \n",
    "def vidToPngs(video_path, output_dir=None, indices_to_match=[], name_from_folder=True):\n",
    "    frame_index = 0\n",
    "    frame_counter = 0\n",
    "    if name_from_folder:\n",
    "        out_name = os.path.splitext(os.path.basename(video_path))[0]\n",
    "    else:\n",
    "        out_name = 'img'\n",
    "    if output_dir==None:\n",
    "        out_dir = os.path.join(os.path.dirname(video_path),out_name)\n",
    "    else:\n",
    "        out_dir = output_dir\n",
    "    if not os.path.exists(out_dir):\n",
    "        os.mkdir(out_dir)\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_width = int(cap.get(3))\n",
    "    frame_height = int(cap.get(4))\n",
    "    frame_rate = round(cap.get(5),2)\n",
    "    while(cap.isOpened()):\n",
    "        ret, frame = cap.read()\n",
    "        frame_counter += 1\n",
    "        if ret == True:\n",
    "            if indices_to_match and not frame_index in indices_to_match:\n",
    "                frame_index += 1\n",
    "                continue\n",
    "            else:\n",
    "                png_name = out_name+str(frame_index).zfill(4)+'.png'\n",
    "                png_path = os.path.join(out_dir, png_name)\n",
    "                cv2.imshow('frame',frame)\n",
    "                cv2.imwrite(png_path, frame)\n",
    "                frame_counter = 0                \n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                        break\n",
    "                frame_index += 1\n",
    "        else: \n",
    "            break\n",
    "                \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vidToPngs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-f4723495d277>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mvidToPngs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\"Z:\\lab\\NSF forelimb project\\Phil_lab\\dlc-data-swap\\c1_11Apr.mp4\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34mr\"C:\\Users\\LabAdmin\\Desktop\\c1\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcodec\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'uncompressed'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mvidToPngs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\"Z:\\lab\\NSF forelimb project\\Phil_lab\\dlc-data-swap\\c2_11Apr.mp4\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34mr\"C:\\Users\\LabAdmin\\Desktop\\c2\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcodec\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'uncompressed'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'vidToPngs' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def matchFrames(extracted_dir):\n",
    "    extracted_files = scanDir(extracted_dir, extension='png') \n",
    "    extracted_indices = [int(os.path.splitext(os.path.basename(png))[0][3:].lstrip('0')) for png in extracted_files]\n",
    "    return extracted_indices   \n",
    "\n",
    "def extractMatchedFrames(indices, output_dir = None, src_vids=[]):\n",
    "    for video in src_vids:\n",
    "        out_name = os.path.splitext(os.path.basename(video))[0]+'_matched'\n",
    "        if output_dir is not None:\n",
    "            output = output_dir\n",
    "        else:\n",
    "            output = os.path.join(os.path.dirname(video),out_name)\n",
    "        vidToPngs(video, output, indices_to_match=extracted_indices, name_from_folder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
