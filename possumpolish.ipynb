{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import imutils\n",
    "from datetime import datetime as dt\n",
    "import os\n",
    "import blend_modes\n",
    "import re\n",
    "\n",
    "\n",
    "\n",
    "input_dir = \"/Users/phil/Desktop/Working/Digitizing/23Apr18.LaiRegnault.SEP85.LS.biceps_teres_lat/run3circles_90-35-4ms\"\n",
    "\n",
    "comp_codec = 'avc1'\n",
    "raw_codec = 'I420'\n",
    "\n",
    "fps = 30\n",
    "vid_res = \"1024x1024\"\n",
    "vid_frames = 800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### USE THIS\n",
    "\n",
    "def scanDir(directory, template=\".\"):\n",
    "    vid_list=[]\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for name in files:\n",
    "            if name.endswith(\".avi\") and not re.search(template,name):\n",
    "                filename = os.path.join(root, name)\n",
    "                print(\"Found XROMM video: \" + filename)\n",
    "                vid_list.append(filename)\n",
    "                continue\n",
    "            else:\n",
    "                continue\n",
    "    return(vid_list)\n",
    "\n",
    "def trimVid(vid_list, length, codec='I420'):\n",
    "    for video in vid_list:\n",
    "        name = video.split(\"/\")[-1]\n",
    "        root = video.replace(name,'')\n",
    "        output_vid = root+\"robo_trim_\"+name.replace(\" \", \"\")\n",
    "        cap = cv2.VideoCapture(video)    \n",
    "        fourcc = cv2.VideoWriter_fourcc(*codec)\n",
    "        out = cv2.VideoWriter(output_vid,fourcc, 30.0, (1024,1024))\n",
    "        starttime = dt.now()\n",
    "        index = 0\n",
    "        while(cap.isOpened()):\n",
    "            ret, frame = cap.read()\n",
    "            if ret==True:\n",
    "                if index < length:\n",
    "                    out.write(frame)\n",
    "                    index += 1\n",
    "            else:\n",
    "                break\n",
    "        endtime = dt.now()\n",
    "        cap.release()\n",
    "        out.release()\n",
    "        print(\"Trimmed \"+output_vid+\" to \"+str(length)+\" frames in {}.\".format(endtime-starttime))\n",
    "        \n",
    "def compressVid(vid_list, codec='avc1'):\n",
    "    for video in vid_list:\n",
    "        name = video.split(\"/\")[-1]\n",
    "        root = video.replace(name,'')\n",
    "        output_vid = root+\"robo_comp_\"+name.replace(\" \", \"\")\n",
    "        cap = cv2.VideoCapture(video)    \n",
    "        fourcc = cv2.VideoWriter_fourcc(*codec)\n",
    "        out = cv2.VideoWriter(output_vid,fourcc, 30.0, (1024,1024))\n",
    "        starttime = dt.now()\n",
    "        index = 0\n",
    "        while(cap.isOpened()):\n",
    "            ret, frame = cap.read()\n",
    "            if ret==True:\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "                clahe = cv2.createCLAHE(clipLimit=3, tileGridSize= (64,64))\n",
    "                frame = clahe.apply(frame)\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_GRAY2BGR)  \n",
    "                out.write(frame)\n",
    "            else:\n",
    "                break\n",
    "        endtime = dt.now()\n",
    "        cap.release()\n",
    "        out.release()\n",
    "        print(\"Compressed \"+output_vid+\" in {}.\".format(endtime-starttime))\n",
    "        \n",
    "def enhanceVid(vid_list, codec='MJPG'):\n",
    "    for video in vid_list:\n",
    "        name = video.split(\"/\")[-1]\n",
    "        root = video.replace(name,'')\n",
    "        output_clahe = root+\"robo_CLAHE_\"+name.replace(\" \", \"\")\n",
    "        output_eroded = root+\"robo_CLAHE_eroded_\"+name.replace(\" \", \"\")\n",
    "        output_dilated = root+\"robo_CLAHE_dilated_\"+name.replace(\" \", \"\")\n",
    "        output_opened = root+\"robo_CLAHE_opened_\"+name.replace(\" \", \"\")\n",
    "        output_dodge = root+\"robo_CLAHE_dodge_\"+name.replace(\" \", \"\")\n",
    "        output_softlight = root+\"robo_CLAHE_softlight_\"+name.replace(\" \", \"\")\n",
    "        output_screen = root+\"robo_CLAHE_screen_\"+name.replace(\" \", \"\")\n",
    "        output_highlight = root+\"robo_CLAHE_highlight_\"+name.replace(\" \", \"\")\n",
    "\n",
    "        cap = cv2.VideoCapture(video)    \n",
    "        fourcc = cv2.VideoWriter_fourcc(*codec)\n",
    "        \n",
    "        out_clahe = cv2.VideoWriter(output_clahe,fourcc, 30.0, (1024,1024))\n",
    "        out_eroded = cv2.VideoWriter(output_eroded,fourcc, 30.0, (1024,1024))\n",
    "        out_dilated = cv2.VideoWriter(output_dilated,fourcc, 30.0, (1024,1024))\n",
    "        out_opened = cv2.VideoWriter(output_opened,fourcc, 30.0, (1024,1024))\n",
    "        out_dodge = cv2.VideoWriter(output_dodge,fourcc, 30.0, (1024,1024))\n",
    "        out_softlight = cv2.VideoWriter(output_softlight,fourcc, 30.0, (1024,1024))\n",
    "        out_screen = cv2.VideoWriter(output_screen,fourcc, 30.0, (1024,1024))       \n",
    "        out_highlight = cv2.VideoWriter(output_highlight,fourcc, 30.0, (1024,1024))\n",
    "        \n",
    "        starttime = dt.now()\n",
    "        index = 0\n",
    "        while(cap.isOpened()):\n",
    "            ret, frame = cap.read()\n",
    "            if ret==True:\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "                clahe = cv2.createCLAHE(clipLimit=2, tileGridSize= (64,64))\n",
    "                frame_clahe = clahe.apply(frame)\n",
    "            \n",
    "                kernel3 = np.ones((3,3),np.uint8)\n",
    "                kernel5 = np.ones((5,5),np.uint8)\n",
    "                kernel9 = np.ones((9,9),np.uint8)\n",
    "                kernel17 = np.ones((17,17),np.uint8)\n",
    "                kernel25 = np.ones((25,25),np.uint8)\n",
    "                \n",
    "                frame_dilated3 = cv2.dilate(frame_clahe,kernel3,iterations = 1)\n",
    "                frame_eroded3 = cv2.erode(frame_clahe,kernel3,iterations = 1)  \n",
    "                \n",
    "                frame_eroded5 = cv2.erode(frame_clahe,kernel5,iterations = 1)\n",
    "                frame_eroded9 = cv2.erode(frame_clahe,kernel9,iterations = 1)\n",
    "                frame_eroded17 = cv2.erode(frame_clahe,kernel17,iterations = 1)  \n",
    "                frame_eroded25 = cv2.erode(frame_clahe,kernel25,iterations = 1)\n",
    "                frame_opened = cv2.dilate(frame_eroded5,kernel3,iterations = 1)\n",
    "                \n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2BGRA,4).astype(np.float32)\n",
    "                frame_clahe = cv2.cvtColor(frame_clahe, cv2.COLOR_BGR2BGRA,4).astype(np.float32)\n",
    "                frame_eroded5 = cv2.cvtColor(frame_eroded5, cv2.COLOR_BGR2BGRA,4).astype(np.float32)\n",
    "                frame_eroded9 = cv2.cvtColor(frame_eroded9, cv2.COLOR_BGR2BGRA,4).astype(np.float32)\n",
    "                frame_eroded17 = cv2.cvtColor(frame_eroded17, cv2.COLOR_BGR2BGRA,4).astype(np.float32)\n",
    "                frame_eroded25 = cv2.cvtColor(frame_eroded25, cv2.COLOR_BGR2BGRA,4).astype(np.float32)\n",
    "                \n",
    "                frame_dodge = blend_modes.dodge(frame_clahe, frame_clahe, 0.5)\n",
    "                frame_softlight = blend_modes.soft_light(frame,frame_clahe,1)\n",
    "                frame_screen = blend_modes.screen(frame,frame_clahe,1)\n",
    "                \n",
    "                frame_highlight = blend_modes.difference(frame, frame_eroded9, 1)\n",
    "                frame_highlight = blend_modes.addition(frame_highlight, frame_clahe,1)\n",
    "                \n",
    "#                 frame_highlight9 = blend_modes.divide(frame,frame_eroded9,1)\n",
    "#                 frame_highlight9 = blend_modes.multiply(frame_highlight9,frame_clahe,1)\n",
    "#                 frame_highlight17 = blend_modes.divide(frame,frame_eroded17,1)\n",
    "#                 frame_highlight17 = blend_modes.multiply(frame_highlight17,frame_clahe,1)\n",
    "#                 frame_highlight25 = blend_modes.divide(frame,frame_eroded25,1)\n",
    "#                 frame_highlight25 = blend_modes.multiply(frame_highlight25,frame_clahe,1)\n",
    "#                 frame_highlight =  blend_modes.soft_light(frame_highlight9, frame_highlight17, 0.5)\n",
    "#                 frame_highlight =  blend_modes.soft_light(frame_highlight, frame_highlight25, 0.5)\n",
    "                \n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGRA2BGR).astype(np.uint8)\n",
    "                frame_clahe = cv2.cvtColor(frame_clahe, cv2.COLOR_BGRA2BGR).astype(np.uint8)\n",
    "                frame_eroded5 = cv2.cvtColor(frame_eroded5, cv2.COLOR_BGRA2BGR).astype(np.uint8)  \n",
    "                frame_opened = cv2.cvtColor(frame_opened, cv2.COLOR_GRAY2BGR)  \n",
    "                frame_dodge = cv2.cvtColor(frame_dodge, cv2.COLOR_BGRA2BGR).astype(np.uint8)  \n",
    "                frame_softlight = cv2.cvtColor(frame_softlight, cv2.COLOR_BGRA2BGR).astype(np.uint8)  \n",
    "                frame_screen = cv2.cvtColor(frame_screen, cv2.COLOR_BGRA2BGR).astype(np.uint8)  \n",
    "                frame_highlight = cv2.cvtColor(frame_highlight, cv2.COLOR_BGRA2BGR).astype(np.uint8)  \n",
    "                \n",
    "                frame_dilated3 = cv2.cvtColor(frame_dilated3, cv2.COLOR_GRAY2BGR)\n",
    "                frame_eroded3 = cv2.cvtColor(frame_eroded3, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                out_clahe.write(frame_clahe)\n",
    "                out_eroded.write(frame_eroded5)\n",
    "                out_opened.write(frame_opened)\n",
    "                out_dodge.write(frame_dodge)\n",
    "                out_softlight.write(frame_softlight)\n",
    "                out_screen.write(frame_screen)\n",
    "                out_highlight.write(frame_highlight)\n",
    "                \n",
    "                out_dilated.write(frame_dilated3)\n",
    "\n",
    "                index += 1\n",
    "#                 print(\"Working on frame: \"+str(index))\n",
    "\n",
    "            else:\n",
    "                break\n",
    "        endtime = dt.now()\n",
    "        cap.release()\n",
    "        out_clahe.release()\n",
    "        out_eroded.release()\n",
    "        out_opened.release()\n",
    "        out_dodge.release()\n",
    "        out_softlight.release()\n",
    "        out_screen.release()\n",
    "        out_highlight.release()\n",
    "        \n",
    "        out_dilated.release()\n",
    "        print(\"Enhanced \"+name+\" in {}.\".format(endtime-starttime))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found XROMM video: /Users/phil/Desktop/Working/Digitizing/23Apr18.LaiRegnault.SEP85.LS.biceps_teres_lat/run3circles_90-35-4ms/Camera No.2.avi\n",
      "Found XROMM video: /Users/phil/Desktop/Working/Digitizing/23Apr18.LaiRegnault.SEP85.LS.biceps_teres_lat/run3circles_90-35-4ms/Camera No.1.avi\n",
      "Enhanced Camera No.2.avi in 0:09:42.036596.\n",
      "Enhanced Camera No.1.avi in 0:09:06.844945.\n"
     ]
    }
   ],
   "source": [
    "# list_to_convert = scanDir(input_dir,\"robo\")\n",
    "# trimVid(list_to_convert, 100)\n",
    "\n",
    "list_to_convert = scanDir(input_dir,\"robo\")\n",
    "enhanceVid(list_to_convert)\n",
    "\n",
    "\n",
    "# list_to_compress = scanDir(input_dir)\n",
    "# compressVid(list_to_compress)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### IMPROVED WITH TRIM FUNCTION\n",
    "filename = \"robo_trimmed\"\n",
    "\n",
    "def scanDir(directory, filter):\n",
    "    vid_list=[]\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for name in files:\n",
    "            if name.endswith(\".avi\") and name.find(filter)>=1:\n",
    "                filename = os.path.join(root, name)\n",
    "                print(\"Found XROMM video: \" + filename)\n",
    "                vid_list.append(filename)\n",
    "                continue\n",
    "            else:\n",
    "                continue\n",
    "    return(vid_list)\n",
    "\n",
    "def trimVid(vid_list, length, codec='I420'):\n",
    "    for video in vid_list:\n",
    "        root = video.replace(video.split(\"/\")[-1],'')\n",
    "        output_vid = root+\"robo_trimmed\"+'_'+video[-5:]\n",
    "        cap = cv2.VideoCapture(video)    \n",
    "        fourcc = cv2.VideoWriter_fourcc(*codec)\n",
    "        out = cv2.VideoWriter(output_vid,fourcc, 30.0, (1024,1024))\n",
    "        starttime = dt.now()\n",
    "        index = 0\n",
    "        while(cap.isOpened()):\n",
    "            ret, frame = cap.read()\n",
    "            if ret==True:\n",
    "                if index < length:\n",
    "                    out.write(frame)\n",
    "                    index += 1\n",
    "            else:\n",
    "                break\n",
    "        endtime = dt.now()\n",
    "        cap.release()\n",
    "        out.release()\n",
    "        print(\"Trimmed \"+output_vid+\" to \"+str(length)+\" frames in {}.\".format(endtime-starttime))\n",
    "        \n",
    "def enhanceVid(vid_list, codec='I420'):\n",
    "    for video in vid_list:\n",
    "        root = video.replace(video.split(\"/\")[-1],'')\n",
    "        output_vid = root+\"robo_enhanced\"+'_'+video[-5:]\n",
    "        cap = cv2.VideoCapture(video)    \n",
    "        fourcc = cv2.VideoWriter_fourcc(*codec)\n",
    "        out = cv2.VideoWriter(output_vid,fourcc, 30.0, (1024,1024))\n",
    "        starttime = dt.now()\n",
    "        index = 0\n",
    "        while(cap.isOpened()):\n",
    "            ret, frame = cap.read()\n",
    "            if ret==True:\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "                frame = cv2.fastNlMeansDenoising(frame,None,3,3,3)\n",
    "                clahe = cv2.createCLAHE(clipLimit=3, tileGridSize= (64,64))\n",
    "                frame_clahe = clahe.apply(frame)\n",
    "                kernel = np.ones((37,37),np.uint8)\n",
    "                frame_eroded = cv2.erode(frame_clahe,kernel,iterations = 1)\n",
    "                frame_eroded = cv2.bitwise_not(frame_eroded)\n",
    "\n",
    "                ###blend-modes requires float32_BGRA data\n",
    "                frame_clahe_float = cv2.cvtColor(frame_clahe, cv2.COLOR_BGR2BGRA).astype(np.float32)\n",
    "                frame_eroded_float=cv2.cvtColor(frame_eroded, cv2.COLOR_BGR2BGRA).astype(np.float32)\n",
    "\n",
    "                blend =  blend_modes.multiply(frame_clahe_float,frame_eroded_float,1)               \n",
    "                ###cv.write needs uint8_BGR data###\n",
    "                blend = cv2.cvtColor(blend, cv2.COLOR_BGRA2BGR)\n",
    "                blend = blend.astype(np.uint8)\n",
    "                out.write(blend)\n",
    "                index += 1\n",
    "#                 print(\"Working on frame: \"+str(index))\n",
    "\n",
    "            else:\n",
    "                break\n",
    "        endtime = dt.now()\n",
    "        cap.release()\n",
    "        out.release()\n",
    "        print(\"Made \"+output_vid+\" in {}.\".format(endtime-starttime))\n",
    "        \n",
    "\n",
    "##31x31kernel invert works well with 1.0 multiply blend and xray COM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##WORKING! CREATES 3 FILES\n",
    "def scanDir(directory, filter):\n",
    "    vid_list=[]\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for name in files:\n",
    "            if name.endswith(\".avi\") and name.find(filter) == -1:\n",
    "                filename = os.path.join(root, name)\n",
    "                print(\"Found XROMM video: \" + filename)\n",
    "                vid_list.append(filename)\n",
    "                continue\n",
    "            else:\n",
    "                continue\n",
    "    return(vid_list)\n",
    "\n",
    "def makeNewVids(vid_list):\n",
    "    for video in vid_list:\n",
    "        root = video.replace(video.split(\"/\")[-1],'')\n",
    "        v1_filename = root+prepend_v1+'_'+video[-5:]\n",
    "        v2_filename = root+prepend_v2+'_'+video[-5:]\n",
    "        v3_filename = root+prepend_v3+'_'+video[-5:]\n",
    "        enhanceVid(video, v1_filename, 'I420')\n",
    "        enhanceVid(video, v2_filename, 'I420', erode=1)\n",
    "        enhanceVid(video, v3_filename, 'jpeg')\n",
    "\n",
    "def enhanceVid(input_vid, output_vid, codec, erode=0):\n",
    "    cap = cv2.VideoCapture(input_vid)    \n",
    "    fourcc = cv2.VideoWriter_fourcc(*codec)\n",
    "    out = cv2.VideoWriter(output_vid,fourcc, 30.0, (1024,1024))\n",
    "    starttime = dt.now()\n",
    "    while(cap.isOpened()):\n",
    "        ret, frame = cap.read()\n",
    "        if ret==True:\n",
    "            if codec=='jpeg':\n",
    "                out.write(frame)\n",
    "            else:                \n",
    "                frame = cv2.fastNlMeansDenoising(frame,None,3,3,3)\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "                clahe = cv2.createCLAHE(clipLimit=3, tileGridSize= (64,64))\n",
    "                frame = clahe.apply(frame)\n",
    "                if erode==1:\n",
    "                    kernel = np.ones((5,5),np.uint8)\n",
    "                    frame = cv2.erode(frame,kernel,iterations = 1)\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_GRAY2BGR)\n",
    "                out.write(frame)\n",
    "        else:\n",
    "            break\n",
    "    endtime = dt.now()\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    print(\"Made \"+output_vid+\" in {}.\".format(endtime-starttime))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TEST: MULTIFRAME DENOISING...try 5,3,2 for params 2 being temporal\n",
    "## RESULT: NOT MUCH DIFFERENCE, 4X COMPUTING TIME...DONT BOTHER\n",
    "\n",
    "prepend_v2 = \"comp_multiframe_denoise\"\n",
    "# prepend_v2 = \"comp_singleframe_denoise\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def scanDir(directory, filter):\n",
    "    vid_list=[]\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for name in files:\n",
    "            if name.endswith(\".avi\") and name.find(filter) == -1:\n",
    "                filename = os.path.join(root, name)\n",
    "                print(\"Found XROMM video: \" + filename)\n",
    "                vid_list.append(filename)\n",
    "                continue\n",
    "            else:\n",
    "                continue\n",
    "    return(vid_list)\n",
    "\n",
    "def makeNewVids(vid_list):\n",
    "    for video in vid_list:\n",
    "        root = video.replace(video.split(\"/\")[-1],'')\n",
    "        v1_filename = root+prepend_v1+'_'+video[-5:]\n",
    "        v2_filename = root+prepend_v2+'_'+video[-5:]\n",
    "        enhanceVid(video, v2_filename, raw_codec)\n",
    "        \n",
    "def enhanceVid(input_vid, output_vid, codec):\n",
    "    cap = cv2.VideoCapture(input_vid)    \n",
    "    fourcc = cv2.VideoWriter_fourcc(*codec)\n",
    "    out = cv2.VideoWriter(output_vid,fourcc, 30.0, (1024,1024))\n",
    "    starttime = dt.now()\n",
    "    index = 0\n",
    "    buffer = []\n",
    "    readingframe = []\n",
    "    while(cap.isOpened()):\n",
    "        ret,frame = cap.read()\n",
    "        if ret==True:\n",
    "            buffer.append(frame)\n",
    "            if index < 3 or index > vid_frames-2:\n",
    "                readingframe = [buffer[index],buffer[index],buffer[index]]\n",
    "            else:\n",
    "                readingframe = [buffer[index-2],buffer[index-1],buffer[index]]\n",
    "            frame = cv2.fastNlMeansDenoisingMulti(readingframe, 1, 3, None, 1, 3, 3)\n",
    "\n",
    "#             frame = cv2.fastNlMeansDenoising(frame,None,3,3,3)\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            \n",
    "            \n",
    "\n",
    "            clahe = cv2.createCLAHE(clipLimit=3, tileGridSize= (64,64))\n",
    "            frame = clahe.apply(frame)\n",
    "#             kernel = np.ones((5,5),np.uint8)\n",
    "#             frame_eroded = cv2.erode(frame,kernel,iterations = 1)\n",
    "#             frame_new = cv2.addWeighted(frame,0.6,frame_eroded,0.4,0)\n",
    "\n",
    "#             frame_new = cv2.cvtColor(frame_new, cv2.COLOR_GRAY2BGR)\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_GRAY2BGR)\n",
    "            index += 1\n",
    "            out.write(frame)\n",
    "        else:\n",
    "            break\n",
    "    endtime = dt.now()\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    print(\"Made \"+output_vid+\" in {}.\".format(endtime-starttime))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TEST: COMBINE 2 LAYERS\n",
    "##RESULT: LOOKS GREAT, DOESN'T TRACK GREAT. VULNERABLE TO OCCLUSION OR NEAR-MISSES\n",
    "\n",
    "prepend_v2 = \"uncomp_erode_stack\"\n",
    "\n",
    "\n",
    "def scanDir(directory, filter):\n",
    "    vid_list=[]\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for name in files:\n",
    "            if name.endswith(\".avi\") and name.find(filter) == -1:\n",
    "                filename = os.path.join(root, name)\n",
    "                print(\"Found XROMM video: \" + filename)\n",
    "                vid_list.append(filename)\n",
    "                continue\n",
    "            else:\n",
    "                continue\n",
    "    return(vid_list)\n",
    "\n",
    "def makeNewVids(vid_list):\n",
    "    for video in vid_list:\n",
    "        root = video.replace(video.split(\"/\")[-1],'')\n",
    "        v1_filename = root+prepend_v1+'_'+video[-5:]\n",
    "        v2_filename = root+prepend_v2+'_'+video[-5:]\n",
    "        enhanceVid(video, v2_filename, 'I420')\n",
    "        \n",
    "def enhanceVid(input_vid, output_vid, codec):\n",
    "    cap = cv2.VideoCapture(input_vid)    \n",
    "    fourcc = cv2.VideoWriter_fourcc(*codec)\n",
    "    out = cv2.VideoWriter(output_vid,fourcc, 30.0, (1024,1024))\n",
    "    starttime = dt.now()\n",
    "    while(cap.isOpened()):\n",
    "        ret, frame = cap.read()\n",
    "        if ret==True:\n",
    "            frame = cv2.fastNlMeansDenoising(frame,None,3,3,3)\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            clahe = cv2.createCLAHE(clipLimit=3, tileGridSize= (64,64))\n",
    "            frame = clahe.apply(frame)\n",
    "            kernel = np.ones((5,5),np.uint8)\n",
    "            frame_eroded = cv2.erode(frame,kernel,iterations = 1)\n",
    "            frame_new = cv2.addWeighted(frame,0.6,frame_eroded,0.4,0)\n",
    "\n",
    "            frame_new = cv2.cvtColor(frame_new, cv2.COLOR_GRAY2BGR)\n",
    "            out.write(frame_new)\n",
    "        else:\n",
    "            break\n",
    "    endtime = dt.now()\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    print(\"Made \"+output_vid+\" in {}.\".format(endtime-starttime))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "small blocksize parameter (<15) with adaptive threshold makes faint beads disappear\n",
    "3-4 are considered extreme values for CLAHE clip limit\n",
    "tilegridsize in CLAHE must > size of features \n",
    "erosion with a 3,3 kernel makes video blocky, helps with sensor noise. don't bother denoising. 2 passes makes big markers, works pretty well with 3-64 clahe. equivalent to 1-pass 5x5\n",
    "31x31 kernel is about the size of default searchwindow in xmalab\n",
    "mjpeg is better than h264 for compression quality, similar filesize\n",
    "denoising: less is better. 2,7,21 is equivalent to 5+,3,3\n",
    "dilation: doenst work to separate occcluding markers: become too small to track"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## denoise tests ##\n",
    "- 2-3-9 = 3-3-3\n",
    "- 2-5-13 slightly better\n",
    "- 21 last param seems bad, blurs details too much \n",
    "- 4-9-21 is unusable\n",
    "- All are better than baseline\n",
    "- 0-0-0 (Clahe without denoise) is better than baseline, worse than 333?\n",
    "- 1-3-3 is better than 2-3-3, 3-3-3 better than both\n",
    "- Test against 2-64x64 CLAHE with 3-3-3:\n",
    "    - 1-8: worse, similar to baseline\n",
    "    - 2-16: worse, better than 1-8, strong on dense scapular bead\n",
    "    - 2.5-24: worse than 2-16\n",
    "    - 3-16: worse, worse than 2-16\n",
    "    - 4-16: on par with 2-16\n",
    "- Test against 2-64x64 CLAHE with 3-3-3:\n",
    "    - 1-128: much worse\n",
    "    - 2-128: also worse\n",
    "    - 2-96: bad: moving tiles\n",
    "Adaptive threshold test:\n",
    "- Gaussian > mean\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## speed tests\n",
    "### cervical bead:\n",
    "- baseline: 8.33fps\n",
    "- compressed: 5.95fps\n",
    "- CLAHEerode: 8.33fps\n",
    "- CLAHE: 8.08fps\n",
    "### distal radius (to f300):\n",
    "- CLAHEerode: 3.33fps\n",
    "- CLAHE: 0.44fps\n",
    "- baseline: 2.5fps\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### TEST: COMBINE 2 LAYERS (INVERT)\n",
    "## RESULT: LOOKS COOL BUT DOESN\"T REALLY HELP\n",
    "\n",
    "prepend_v2 = \"uncomp_erode_stack_invert_add\"\n",
    "\n",
    "\n",
    "def scanDir(directory, filter):\n",
    "    vid_list=[]\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for name in files:\n",
    "            if name.endswith(\".avi\") and name.find(filter) == -1:\n",
    "                filename = os.path.join(root, name)\n",
    "                print(\"Found XROMM video: \" + filename)\n",
    "                vid_list.append(filename)\n",
    "                continue\n",
    "            else:\n",
    "                continue\n",
    "    return(vid_list)\n",
    "\n",
    "def makeNewVids(vid_list):\n",
    "    for video in vid_list:\n",
    "        root = video.replace(video.split(\"/\")[-1],'')\n",
    "        v1_filename = root+prepend_v1+'_'+video[-5:]\n",
    "        v2_filename = root+prepend_v2+'_'+video[-5:]\n",
    "        enhanceVid(video, v2_filename, 'I420')\n",
    "        \n",
    "def enhanceVid(input_vid, output_vid, codec):\n",
    "    cap = cv2.VideoCapture(input_vid)    \n",
    "    fourcc = cv2.VideoWriter_fourcc(*codec)\n",
    "    out = cv2.VideoWriter(output_vid,fourcc, 30.0, (1024,1024))\n",
    "    starttime = dt.now()\n",
    "    while(cap.isOpened()):\n",
    "        ret, frame = cap.read()\n",
    "        if ret==True:\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            frame = cv2.fastNlMeansDenoising(frame,None,3,3,3)\n",
    "            clahe = cv2.createCLAHE(clipLimit=3, tileGridSize= (64,64))\n",
    "            frame = clahe.apply(frame)\n",
    "            kernel = np.ones((9,9),np.uint8)\n",
    "            frame_eroded = cv2.erode(frame,kernel,iterations = 1)\n",
    "            frame_eroded = cv2.bitwise_not(frame_eroded)\n",
    "            frame_eroded = cv2.equalizeHist(frame_eroded).astype(\"float32\")\n",
    "#             frame_new = cv2.addWeighted(frame,0.75,frame_eroded,0.25,0)\n",
    "            \n",
    "            frame_new = cv2.cvtColor(frame, cv2.COLOR_GRAY2RGBA, 4)\n",
    "            frame_eroded = cv2.cvtColor(frame_eroded, cv2.COLOR_GRAY2RGBA,4)\n",
    "            frame_new = blend_modes.multiply(frame_new, frame_eroded, 1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "            out.write(frame_new)\n",
    "        else:\n",
    "            break\n",
    "    endtime = dt.now()\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    print(\"Made \"+output_vid+\" in {}.\".format(endtime-starttime))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cap = cv2.VideoCapture(input_path)\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "## working fourcc codecs per https://gist.github.com/takuma7/44f9ecb028ff00e2132e:\n",
    "## 'avc1' = h.264; 'jpeg' = jpeg; 'mp4v' = mpeg4; 'raw' = uncompressed; 'tiff' = tiff, semi-working\n",
    "fourcc = cv2.VideoWriter_fourcc(*'I420')\n",
    "out = cv2.VideoWriter(output_path,fourcc, 30.0, (1024,1024))\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret==True:\n",
    "        frame = cv2.fastNlMeansDenoising(frame,None,2,3,3)\n",
    "        kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])\n",
    "        frame = cv2.filter2D(frame, -1, kernel)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        clahe = cv2.createCLAHE(clipLimit=2, tileGridSize= (64,64))\n",
    "        frame = clahe.apply(frame)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_GRAY2BGR)\n",
    "        # write the flipped frame\n",
    "        out.write(frame)\n",
    "\n",
    "#         cv2.imshow('frame',frame)\n",
    "#         if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#             break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# Release everything if job is finished\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##LUCAS-KANADE TRACKER\n",
    "cap_lk = cv2.VideoCapture(output_path)\n",
    "# Create old frame\n",
    "_, frame = cap_lk.read()\n",
    "old_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "# Lucas kanade params\n",
    "lk_params = dict(winSize = (8, 8),\n",
    "                 maxLevel = 4,\n",
    "                 criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 30, 0.03))\n",
    "# Mouse function\n",
    "def select_point(event, x, y, flags, params):\n",
    "    global point, point_selected, old_points\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        point = (x, y)\n",
    "        point_selected = True\n",
    "        old_points = np.array([[x, y]], dtype=np.float32)\n",
    "cv2.namedWindow(\"Frame\")\n",
    "cv2.setMouseCallback(\"Frame\", select_point)\n",
    "point_selected = False\n",
    "point = ()\n",
    "old_points = np.array([[]])\n",
    "while True:\n",
    "    _, frame = cap_lk.read()\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    if point_selected is True:\n",
    "        cv2.circle(frame, point, 5, (0, 0, 255), 2)\n",
    "        new_points, status, error = cv2.calcOpticalFlowPyrLK(old_gray, gray_frame, old_points, None, **lk_params)\n",
    "        old_gray = gray_frame.copy()\n",
    "        old_points = new_points\n",
    "        x, y = new_points.ravel()\n",
    "        cv2.circle(frame, (x, y), 5, (0, 255, 0), -1)\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:\n",
    "        break\n",
    "cap_lk.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OTHER TRACKERS\n",
    "# import the necessary packages\n",
    "from imutils.video import VideoStream\n",
    "import argparse\n",
    "import imutils\n",
    "import time\n",
    "import cv2\n",
    "\n",
    "\n",
    "# initialize a dictionary that maps strings to their corresponding\n",
    "# OpenCV object tracker implementations\n",
    "OPENCV_OBJECT_TRACKERS = {\n",
    "    \"csrt\": cv2.TrackerCSRT_create,\n",
    "    \"kcf\": cv2.TrackerKCF_create,\n",
    "    \"boosting\": cv2.TrackerBoosting_create,\n",
    "    \"mil\": cv2.TrackerMIL_create,\n",
    "    \"tld\": cv2.TrackerTLD_create,\n",
    "    \"medianflow\": cv2.TrackerMedianFlow_create,\n",
    "    \"mosse\": cv2.TrackerMOSSE_create\n",
    "}\n",
    " \n",
    "# initialize OpenCV's special multi-object tracker\n",
    "trackers = cv2.MultiTracker_create()\n",
    "\n",
    "vs = cv2.VideoCapture(output_path)\n",
    "tracker_choice = \"csrt\"\n",
    "    \n",
    "# loop over frames from the video stream\n",
    "while True:\n",
    "    # grab the current frame, then handle if we are using a\n",
    "    # VideoStream or VideoCapture object\n",
    "    frame = vs.read()\n",
    "    _, frame = vs.read()\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    " \n",
    "    # check to see if we have reached the end of the stream\n",
    "    if frame is None:\n",
    "        break\n",
    " \n",
    "    # resize the frame (so we can process it faster)\n",
    "#     frame = imutils.resize(frame, width=600)\n",
    "    \n",
    "    \n",
    "    # grab the updated bounding box coordinates (if any) for each\n",
    "    # object that is being tracked\n",
    "    (success, boxes) = trackers.update(frame)\n",
    "\n",
    "    # loop over the bounding boxes and draw then on the frame\n",
    "    for box in boxes:\n",
    "        (x, y, w, h) = [int(v) for v in box]\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        \n",
    "    # show the output frame\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    # if the 's' key is selected, we are going to \"select\" a bounding\n",
    "    # box to track\n",
    "    if key == ord(\"s\"):\n",
    "        # select the bounding box of the object we want to track (make\n",
    "        # sure you press ENTER or SPACE after selecting the ROI)\n",
    "        box = cv2.selectROI(\"Frame\", frame, fromCenter=False,\n",
    "            showCrosshair=True)\n",
    "\n",
    "        # create a new object tracker for the bounding box and add it\n",
    "        # to our multi-object tracker\n",
    "        tracker = OPENCV_OBJECT_TRACKERS[tracker_choice]()\n",
    "        trackers.add(tracker, frame, box)\n",
    "        \n",
    "    # if the `q` key was pressed, break from the loop\n",
    "    elif key == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "\n",
    "# otherwise, release the file pointer\n",
    "\n",
    "vs.release()\n",
    "\n",
    "# close all windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OTHER TRACKERS\n",
    "import cv2\n",
    "import sys\n",
    "  \n",
    "if __name__ == '__main__' :\n",
    " \n",
    "    # Set up tracker.\n",
    "    # Instead of MIL, you can also use\n",
    " \n",
    "    tracker_types = ['BOOSTING', 'MIL','KCF', 'TLD', 'MEDIANFLOW', 'GOTURN', 'MOSSE', 'CSRT']\n",
    "    tracker_type = tracker_types[]\n",
    " \n",
    "    if tracker_type == 'BOOSTING':\n",
    "        tracker = cv2.TrackerBoosting_create()\n",
    "    if tracker_type == 'MIL':\n",
    "        tracker = cv2.TrackerMIL_create()\n",
    "    if tracker_type == 'KCF':\n",
    "        tracker = cv2.TrackerKCF_create()\n",
    "    if tracker_type == 'TLD':\n",
    "        tracker = cv2.TrackerTLD_create()\n",
    "    if tracker_type == 'MEDIANFLOW':\n",
    "        tracker = cv2.TrackerMedianFlow_create()\n",
    "    if tracker_type == 'GOTURN':\n",
    "        tracker = cv2.TrackerGOTURN_create()\n",
    "    if tracker_type == 'MOSSE':\n",
    "        tracker = cv2.TrackerMOSSE_create()\n",
    "    if tracker_type == \"CSRT\":\n",
    "        tracker = cv2.TrackerCSRT_create()\n",
    " \n",
    "    # Read video\n",
    "    video = cv2.VideoCapture(input_path)\n",
    " \n",
    "    # Exit if video not opened.\n",
    "    if not video.isOpened():\n",
    "        print(\"Could not open video\")\n",
    "        sys.exit()\n",
    " \n",
    "    # Read first frame.\n",
    "    ok, frame = video.read()\n",
    "    if not ok:\n",
    "        print('Cannot read video file')\n",
    "        sys.exit()\n",
    "     \n",
    "    # Define an initial bounding box\n",
    "#     bbox = (287, 23, 86, 320)\n",
    " \n",
    "    # Uncomment the line below to select a different bounding box\n",
    "    bbox = cv2.selectROI(frame, False)\n",
    " \n",
    "    # Initialize tracker with first frame and bounding box\n",
    "    ok = tracker.init(frame, bbox)\n",
    " \n",
    "    while True:\n",
    "        # Read a new frame\n",
    "        ok, frame = video.read()\n",
    "        if not ok:\n",
    "            break\n",
    "         \n",
    "        # Start timer\n",
    "        timer = cv2.getTickCount()\n",
    " \n",
    "        # Update tracker\n",
    "        ok, bbox = tracker.update(frame)\n",
    " \n",
    "        # Calculate Frames per second (FPS)\n",
    "        fps = cv2.getTickFrequency() / (cv2.getTickCount() - timer);\n",
    " \n",
    "        # Draw bounding box\n",
    "        if ok:\n",
    "            # Tracking success\n",
    "            p1 = (int(bbox[0]), int(bbox[1]))\n",
    "            p2 = (int(bbox[0] + bbox[2]), int(bbox[1] + bbox[3]))\n",
    "            cv2.rectangle(frame, p1, p2, (255,0,0), 2, 1)\n",
    "        else :\n",
    "            # Tracking failure\n",
    "            cv2.putText(frame, \"Tracking failure detected\", (100,80), cv2.FONT_HERSHEY_SIMPLEX, 0.75,(0,0,255),2)\n",
    " \n",
    "        # Display tracker type on frame\n",
    "        cv2.putText(frame, tracker_type + \" Tracker\", (100,20), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (50,170,50),2);\n",
    "     \n",
    "        # Display FPS on frame\n",
    "        cv2.putText(frame, \"FPS : \" + str(int(fps)), (100,50), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (50,170,50), 2);\n",
    " \n",
    "        # Display result\n",
    "        cv2.imshow(\"Tracking\", frame)\n",
    " \n",
    "        # Exit if ESC pressed\n",
    "        k = cv2.waitKey(1) & 0xff\n",
    "        if k == 27 : break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TESTING CLAHE PARAMETERS\n",
    "img = cv2.imread('/Users/phil/Desktop/clahetest/cam2occluding/clahe_0.png',0)\n",
    "base_path = '/Users/phil/Desktop/clahetest/cam2occluding/clahe_0.png'\n",
    "\n",
    "thresholds = [0.5,1.0,1.5,2.0,2.5,3.0,3.5,4.0,4.5,5.0]\n",
    "tile_sizes = [2,4,8,16,24,32,40,48,56,64,72,80]\n",
    "for threshold in thresholds:\n",
    "    for tile in tile_sizes:\n",
    "        clahe =  cv2.createCLAHE(clipLimit=threshold, tileGridSize=(tile,tile))\n",
    "        cl = clahe.apply(img)\n",
    "        cv2.imwrite(base_path+'clahe'+str(threshold)+'_'+str(tile)+'.jpg',cl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- original is 100f in 11s\n",
    "- avc1 is slooow: 100f in 1:21\n",
    "- jpeg is faster than avc1: 100f in 23s, 5s encode\n",
    "- tiff: 12s encode, width/height mismatch\n",
    "- raw is 5s encode, width/height mismatch\n",
    "- I420 tracks as fast as raw, 5s encode, 50% bigger file\n",
    "- 64tile_single 1,3,3: 26. no sharper than 2,3,3. more false positives\n",
    "- 64tile_single 2,3,3: 26s. looks a lot like 3,3,3, slightly sharper markers. good compromise\n",
    "- 64tile_single 3,3,3: 26s. Good denoise on meat, no effect on bg\n",
    "- 64tile_single 3,5,3: 26s. No change compared to 3,3,3\n",
    "- 64tile_single 3,3,5: 54s. slightly better than 3,5,3\n",
    "- 64tile_single 3,3,11: 3mins exactly. slightly better than 3,3,5, but hard to say exactly\n",
    "- 64tile_single 4,3,3: 26. similar to 3,3,3. too blurry to track well\n",
    "- 64tile_single 5,3,3: 32s. points blurrier than 4,3,3. bad\n",
    "- denoised+clahe tracks better than raw\n",
    "- combo to beat is CLAHE 2,64 | denoise 2,3,3\n",
    "- unsharp mask makes things worse\n",
    "\n",
    "- good xmalab settings with clahe denoise: threshold 8, xray center of mass\n",
    "- pre or post denoise makes no difference?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
