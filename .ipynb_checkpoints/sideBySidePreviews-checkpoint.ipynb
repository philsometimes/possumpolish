{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import *\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import re\n",
    "import importlib\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir=r\"Z:\\lab\\NSF forelimb project\\Phil_lab\\C-arm\\In\"\n",
    "all_avis = scanDir(input_dir,\"avi\")\n",
    "data_avis = [path for path in all_avis if not re.search(\"cube\", path)]\n",
    "nocal_avis = [path for path in data_avis if not re.search(\"cal\", path)]\n",
    "actual_avis = [path for path in nocal_avis if not re.search(\"preview\", path)]\n",
    "raw_avis = [path for path in actual_avis if not re.search(\"robo\", path)]\n",
    "\n",
    "\n",
    "# video_dict = {}\n",
    "# video_dict['A'], video_dict['B'] = scanDir(input_dir, \"avi\")\n",
    "# codec = 0\n",
    "# #substitute 0 in call to videowriter for uncompressed, otherwise cv2.VideoWriter_fourcc(*'mp4v')\n",
    "# ##https://www.microsoft.com/en-us/p/hevc-video-extensions-from-device-manufacturer/9n4wgh0z6vhq?activetab=pivot:overviewtab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z:\\lab\\NSF forelimb project\\Phil_lab\\C-arm\\In\\Oct7_LaiWright\\19_t2_fullstride_B+_HINDLIMB\n",
      "[]\n",
      "Z:\\lab\\NSF forelimb project\\Phil_lab\\C-arm\\In\\Oct7_LaiWright\\19_t2_fullstride_B+_HINDLIMB\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "trial_dirs = list(set([os.path.dirname(path) for path in raw_avis]))\n",
    "trial_dict = {}\n",
    "for directory in trial_dirs:\n",
    "    trial_dir, trial_name = os.path.split(directory)\n",
    "    day_dir, day_name = os.path.split(trial_dir)\n",
    "    day = day_name.split('_',1)[0]\n",
    "    uid = day + '_' + trial_name\n",
    "    avis = [file for file in raw_avis if re.search(day_name, file) and re.search(trial_name,file)]\n",
    "#     print(avis)\n",
    "    cam1 = [os.path.basename(file) for file in avis if re.search('1', os.path.basename(file)[-5:])]\n",
    "    cam2 = [os.path.basename(file) for file in avis if re.search('2', os.path.basename(file)[-5:])]\n",
    "    if len(cam1)!=1:\n",
    "        print(directory)\n",
    "        print(cam1)\n",
    "    if len(cam2)!=1:\n",
    "        print(directory)\n",
    "        print(cam2)\n",
    "    trial_dict[uid] = {\"path\":directory, \"c1\":cam1, \"c2\":cam2}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "done = []\n",
    "for trial in list(trial_dict.keys()):\n",
    "    if trial_dict[trial]['c1'] and trial_dict[trial]['c2'] :\n",
    "        print('creating tandem preview for '+trial_dict[trial]['path'])\n",
    "        tandemPreviews(trial_dict[trial])\n",
    "        done.append(trial)\n",
    "    else:\n",
    "        print('skipping '+trial_dict[trial]['path']+' unpaired camera views')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_trials = {'tegu_lo':'Oct7_8_t4_fullstride_A', \n",
    "               'tegu_hi':'Nov1_5_t1_squeeze_A+',\n",
    "               'possum_lo':'Nov6_12_p1_squeezelow_A',\n",
    "               'possum_hi':'Oct14_9_p4_fullstride_a+',\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# foreach: laplacian, 1-5x kernel\n",
    "def laplacianKernelSearch(video_dict):\n",
    "    fourcc = cv2.VideoWriter_fourcc('m','p','4','v')\n",
    "    capA = cv2.VideoCapture(os.path.join(video_dict['path'],video_dict['c1'][0]))\n",
    "    capB = cv2.VideoCapture(os.path.join(video_dict['path'],video_dict['c2'][0]))\n",
    "    frame_index = 0\n",
    "    frame_width = int(capA.get(3))\n",
    "    frame_height = int(capA.get(4))\n",
    "    frame_rate = round(capA.get(5),2)\n",
    "    input_name =os.path.splitext(video_dict['c1'][0])\n",
    "    output_name = os.path.join(video_dict['path'],(input_name[0][:-1]+'_laplacian'+'.mp4'))\n",
    "    \n",
    "    frameA_yStart = math.floor(frame_height*.1)\n",
    "    frameA_yEnd = math.floor(frame_height*.8)\n",
    "    frameB_yStart = math.floor(frame_height*.3)\n",
    "    frameB_yEnd = math.floor(frame_height)\n",
    "    \n",
    "    output_dims = [frame_width*2, frameA_yEnd-frameA_yStart+frameB_yEnd-frameB_yStart]\n",
    "    out = cv2.VideoWriter(output_name,\n",
    "                         fourcc,\n",
    "                         frame_rate,(output_dims[0], output_dims[1]))\n",
    "    while(capA.isOpened()):\n",
    "        retA, frameA = capA.read()\n",
    "        retB, frameB = capB.read()\n",
    "        frame_index += 1\n",
    "        if retA == True:\n",
    "            frameArotate = imutils.rotate(frameA, 128)\n",
    "            frameAcrop = frameArotate[frameA_yStart:frameA_yEnd,:]\n",
    "            frameBcrop = frameB[frameB_yStart:frameB_yEnd,:]\n",
    "            concatenated = cv2.vconcat([frameAcrop, frameBcrop])\n",
    "            preview = cv2.resize(concatenated, (math.floor(frame_width/2), (math.floor(output_dims[1]/2))))\n",
    "            \n",
    "            gray_img = cv2.cvtColor(preview, cv2.COLOR_BGR2GRAY)\n",
    "            clahe1 = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(32,32))\n",
    "            clahe2 = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(40,40))\n",
    "            cl1 = clahe1.apply(gray_img)\n",
    "            cl2 = clahe2.apply(gray_img)\n",
    "\n",
    "#             blur_img1 = cv2.GaussianBlur(gray_img, (1, 1), 0)\n",
    "#             laplacian1 = cv2.Laplacian(blur_img1, cv2.CV_64F)\n",
    "#             blur_img3 = cv2.GaussianBlur(gray_img, (3, 3), 0)\n",
    "#             laplacian3 = cv2.Laplacian(blur_img3, cv2.CV_64F)\n",
    "#             blur_img5 = cv2.GaussianBlur(gray_img, (5, 5), 0)\n",
    "#             laplacian5 = cv2.Laplacian(blur_img5, cv2.CV_64F)\n",
    "#             edges = cv2.Canny(cl1, 40, 120, 3, L2gradient=True)\n",
    "            combined = cv2.hconcat([gray_img,cl1,cl2])\n",
    "#             labeled1 = cv2.putText(laplacian1, '1x1 laplacian', (20,20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255))\n",
    "#             labeled3 = cv2.putText(laplacian3, '3x3 laplacian', (20,20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255))\n",
    "#             labeled5 = cv2.putText(laplacian5, '5x5 laplacian', (20,20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255))\n",
    "#             both = cv2.hconcat([labeled1, labeled3, labeled5])\n",
    "\n",
    "#             labeled = cv2.putText(preview, video_dict['path'], (20,20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255))\n",
    "#             labeled = cv2.putText(preview, 'FRAME '+str(frame_index), (20,40), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255))\n",
    "#             labeled = cv2.putText(preview, 'DIMS '+str(preview.shape), (20,60), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255))\n",
    "#             cv2.cvtColor(labeled, cv2.COLOR_BGR2GRAY)  \n",
    "            cv2.imshow('test',combined)\n",
    "#             out.write(both)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                frame_index = 0\n",
    "                break\n",
    "        else:\n",
    "            frame_index = 0\n",
    "            break\n",
    "    capA.release()\n",
    "    capB.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# def mergeRGB(video_dict, codec, mode):\n",
    "#     capA = cv2.VideoCapture(video_dict['A'])\n",
    "#     capB = cv2.VideoCapture(video_dict['B'])\n",
    "#     frame_width = int(capA.get(3))\n",
    "#     frame_height = int(capA.get(4))\n",
    "#     frame_rate = round(capA.get(5),2)\n",
    "#     input_name =os.path.splitext(os.path.basename(video_dict['A']))\n",
    "#     output_name = mode+\"_RGBMerge_\"+input_name[0][:-4]+input_name[1]\n",
    "#     out = cv2.VideoWriter(output_name,\n",
    "#                          codec,\n",
    "#                          frame_rate,(frame_width, frame_height))\n",
    "#     while(capA.isOpened()):\n",
    "#         retA, frameA = capA.read()\n",
    "#         retB, frameB = capB.read()\n",
    "#         if retA == True:\n",
    "#             ## give frames an alpha channel to prepare for blending; blend_modes requires 32bit\n",
    "#             frameA = cv2.cvtColor(frameA, cv2.COLOR_BGR2BGRA,4).astype(np.float32)\n",
    "#             frameB = cv2.cvtColor(frameB, cv2.COLOR_BGR2BGRA,4).astype(np.float32)\n",
    "#             if mode == \"difference\":\n",
    "#                 extraChannel = blend_modes.difference(frameA,frameB,1)\n",
    "#             elif mode == \"multiply\":\n",
    "#                 extraChannel = blend_modes.multiply(frameA,frameB,1)\n",
    "#             else:\n",
    "#                 extraChannel = np.zeros((frame_width, frame_height,3),np.uint8)\n",
    "#                 extraChannel = cv2.cvtColor(extraChannel, cv2.COLOR_BGR2BGRA,4).astype(np.float32)\n",
    "\n",
    "#             ## get rid of alpha channel in preparation for converting back to grayscale; opencv prefers 8bit\n",
    "#             frameA = cv2.cvtColor(frameA, cv2.COLOR_BGRA2BGR).astype(np.uint8)  \n",
    "#             frameB = cv2.cvtColor(frameB, cv2.COLOR_BGRA2BGR).astype(np.uint8)  \n",
    "#             extraChannel = cv2.cvtColor(extraChannel, cv2.COLOR_BGRA2BGR).astype(np.uint8)  \n",
    "\n",
    "#             ## convert to grayscale so we can merge into 3-channel image\n",
    "#             frameA = cv2.cvtColor(frameA, cv2.COLOR_BGR2GRAY)  \n",
    "#             frameB = cv2.cvtColor(frameB, cv2.COLOR_BGR2GRAY)  \n",
    "#             extraChannel = cv2.cvtColor(extraChannel, cv2.COLOR_BGR2GRAY)  \n",
    "\n",
    "#             ## merge, show and write                  \n",
    "#             merged = cv2.merge((extraChannel, frameB, frameA))\n",
    "#             cv2.imshow('merged',merged)\n",
    "#             out.write(merged)\n",
    "#             if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#                 break\n",
    "#         else:\n",
    "#             break\n",
    "#     capA.release()\n",
    "#     capB.release()\n",
    "#     out.release()\n",
    "#     cv2.destroyAllWindows()\n",
    "#     print(\"done!\")cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "laplacianKernelSearch(trial_dict[test_trials['tegu_lo']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
